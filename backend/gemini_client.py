"""
Gemini Client - Deep Reasoning with Thinking Traces

Features:
- Multimodal analysis (text, images, PDFs)
- Uses Gemini 2.5 Pro for best quality
- Streaming responses with thought signatures
- Automatic chart/diagram generation
"""

import os
import json
import re
from typing import Dict, Any, List, Optional, AsyncGenerator

from google import genai
from google.genai import types


class GeminiClient:
    """Gemini 2.5 Pro client with deep reasoning capabilities."""
    
    def __init__(self):
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key or api_key == "your_gemini_api_key_here":
            print("âš ï¸  Warning: GEMINI_API_KEY not set. Using mock responses.")
            self.client = None
            self.mock_mode = True
        else:
            self.client = genai.Client(api_key=api_key)
            self.mock_mode = False
        
        # Use the best available Gemini model (gemma-3-27b-it has quota)
        self.model = "gemma-3-27b-it"
        self.fallback_model = "gemma-3-12b-it"
        
        # Enhanced system instruction for bio-research analysis
        self.system_instruction = """You are Helix Mind, an elite autonomous bio-research AI agent designed for scientists, researchers, and graduate students. You combine deep scientific knowledge with advanced analytical capabilities.

## CORE CAPABILITIES

### 1. MULTIMODAL ANALYSIS
- Analyze microscopy images, cell cultures, gel electrophoresis, and experimental data
- Extract insights from research papers, protocols, and clinical documents
- Interpret protein/gene sequences and predict structural implications

### 2. SCIENTIFIC REASONING
- Apply the scientific method: observation â†’ hypothesis â†’ analysis â†’ conclusion
- Cross-reference findings with established literature and databases
- Identify statistical significance and potential confounds

### 3. DATA VISUALIZATION (CRITICAL)
- ALWAYS generate at least 2-3 relevant charts for any analysis
- Use appropriate chart types based on data characteristics
- Provide actionable insights with each visualization

## VISUALIZATION REQUIREMENTS

For EVERY analysis, you MUST include multiple chart blocks in this exact JSON format:

```chart
{
  "type": "bar|line|scatter|heatmap|pie|radar",
  "title": "Descriptive Chart Title",
  "data": {
    "labels": ["Label1", "Label2", ...],
    "values": [number1, number2, ...]
  },
  "insights": "Key scientific finding from this visualization"
}
```

### Chart Type Guidelines:
- **bar**: Comparisons between categories (mutation frequencies, expression levels)
- **line**: Trends over time or continuous variables (time courses, dose-response)
- **scatter**: Correlations between two variables (binding affinity vs. concentration)
- **heatmap**: Gene expression matrices, correlation matrices (use z: [[]], x: [], y: [])
- **pie**: Distribution/composition analysis (pathway involvement, sample categories)
- **radar**: Multi-dimensional comparisons (protein properties, risk factors)

## RESPONSE STRUCTURE

1. **Executive Summary**: Key findings in 2-3 sentences
2. **Detailed Analysis**: Systematic breakdown with scientific terminology
3. **Visualizations**: 2-3 relevant charts with insights
4. **Actionable Recommendations**: Next steps for the researcher
5. **Limitations & Caveats**: Acknowledge uncertainties

## QUALITY STANDARDS

- Be precise, clinical, and action-oriented
- Use proper scientific terminology
- Cite statistical significance where applicable
- Provide confidence levels for predictions
- Always suggest validation experiments
"""

    async def analyze(
        self, 
        context: Dict[str, Any], 
        thinking_level: str = "high"
    ) -> Dict[str, Any]:
        """
        Perform deep multimodal analysis.
        
        Args:
            context: Dict containing query, files, memory, and vector_context
            thinking_level: "none", "low", or "high"
            
        Returns:
            Dict with response, thinking_trace, and chart_data
        """
        if self.mock_mode:
            return self._mock_analysis(context)
        
        # Try real API, fallback to mock on error
        try:
            return await self._real_analyze(context, thinking_level)
        except Exception as e:
            print(f"âš ï¸  API Error with primary model: {e}")
            try:
                # Try fallback model
                self.model = self.fallback_model
                return await self._real_analyze(context, thinking_level)
            except Exception as e2:
                print(f"âš ï¸  Fallback API Error: {e2}. Using mock mode.")
                return self._mock_analysis(context)
    
    async def _real_analyze(
        self, 
        context: Dict[str, Any], 
        thinking_level: str = "high"
    ) -> Dict[str, Any]:
        """Actual API call to Gemini."""
        contents = []
        
        # Build enhanced query with context
        query_parts = [context["query"]]
        
        # Add memory context if available
        if context.get("memory"):
            memory_text = "\n\n--- PAST SESSION CONTEXT ---\n"
            for mem in context["memory"]:
                memory_text += f"â€¢ {mem.get('content', str(mem))}\n"
            query_parts.append(memory_text)
        
        # Add vector context if available
        if context.get("vector_context"):
            vector_text = "\n\n--- RELEVANT RESEARCH KNOWLEDGE ---\n"
            for doc in context["vector_context"]:
                vector_text += f"â€¢ {doc.get('content', str(doc))[:500]}...\n"
            query_parts.append(vector_text)
        
        # Combine into single query
        full_query = "\n".join(query_parts)
        full_query += "\n\n**IMPORTANT: Generate at least 2 relevant data visualizations with actual data values.**"
        
        contents.append(types.Part.from_text(text=full_query))
        
        # Add file contents
        for file in context.get("files", []):
            if file["type"] == "image":
                import base64
                image_data = base64.b64decode(file["data"])
                contents.append(types.Part.from_bytes(
                    data=image_data,
                    mime_type=file["mime_type"]
                ))
            elif file["type"] == "pdf":
                contents.append(types.Part.from_text(
                    text=f"\n\n--- PDF: {file['filename']} ---\n{file['data'][:8000]}"
                ))
            else:
                contents.append(types.Part.from_text(
                    text=f"\n\n--- FILE: {file['filename']} ---\n{file['data'][:5000]}"
                ))
        
        # Check if using Gemma model (doesn't support system_instruction)
        is_gemma = self.model.startswith("gemma")
        
        # For Gemma, prepend system instruction to contents
        if is_gemma:
            system_part = types.Part.from_text(text=f"SYSTEM INSTRUCTIONS:\n{self.system_instruction}\n\n---\nUSER QUERY:\n")
            contents.insert(0, system_part)
            
            config = types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=8192,
                top_p=0.95,
            )
        else:
            config = types.GenerateContentConfig(
                system_instruction=self.system_instruction,
                temperature=0.7,
                max_output_tokens=8192,
                top_p=0.95,
            )
        
        # Generate response
        response = self.client.models.generate_content(
            model=self.model,
            contents=contents,
            config=config
        )
        
        # Extract response
        thinking_trace = []
        response_text = ""
        
        for part in response.candidates[0].content.parts:
            if hasattr(part, 'thought') and part.thought:
                thinking_trace.append(part.text)
            else:
                response_text += part.text
        
        # Extract chart data
        chart_data = self._extract_charts(response_text)
        
        return {
            "response": response_text,
            "thinking_trace": thinking_trace,
            "chart_data": chart_data,
            "model": self.model,
            "thinking_level": thinking_level
        }

    async def analyze_stream(
        self, 
        context: Dict[str, Any], 
        thinking_level: str = "high"
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        Stream analysis results with real-time thinking traces.
        
        Yields chunks with types: 'thinking', 'response', 'chart', 'complete'
        """
        if self.mock_mode:
            async for chunk in self._mock_stream(context):
                yield chunk
            return
        
        # Try real streaming, fallback to mock on error
        try:
            async for chunk in self._real_analyze_stream(context, thinking_level):
                yield chunk
        except Exception as e:
            print(f"âš ï¸  Stream API Error: {e}. Falling back to mock stream.")
            async for chunk in self._mock_stream(context):
                yield chunk
    
    async def _real_analyze_stream(
        self, 
        context: Dict[str, Any], 
        thinking_level: str = "high"
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """Actual streaming API call to Gemini."""
        # Build query
        query_parts = [context["query"]]
        
        if context.get("memory"):
            memory_text = "\n\n--- PAST SESSION CONTEXT ---\n"
            for mem in context["memory"]:
                memory_text += f"â€¢ {mem.get('content', str(mem))}\n"
            query_parts.append(memory_text)
        
        full_query = "\n".join(query_parts)
        full_query += "\n\n**IMPORTANT: Generate at least 2 relevant data visualizations with actual data values.**"
        
        contents = [types.Part.from_text(text=full_query)]
        
        for file in context.get("files", []):
            if file["type"] == "image":
                import base64
                image_data = base64.b64decode(file["data"])
                contents.append(types.Part.from_bytes(
                    data=image_data,
                    mime_type=file["mime_type"]
                ))
            elif file["type"] in ["pdf", "text"]:
                contents.append(types.Part.from_text(
                    text=f"\n\n--- {file['type'].upper()}: {file['filename']} ---\n{file['data'][:8000]}"
                ))
        
        # Check if using Gemma model
        is_gemma = self.model.startswith("gemma")
        
        if is_gemma:
            system_part = types.Part.from_text(text=f"SYSTEM INSTRUCTIONS:\n{self.system_instruction}\n\n---\nUSER QUERY:\n")
            contents.insert(0, system_part)
            
            config = types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=8192,
                top_p=0.95,
            )
        else:
            config = types.GenerateContentConfig(
                system_instruction=self.system_instruction,
                temperature=0.7,
                max_output_tokens=8192,
                top_p=0.95,
            )
        
        # Stream response
        response_text = ""
        
        stream = self.client.models.generate_content_stream(
            model=self.model,
            contents=contents,
            config=config
        )
        
        for chunk in stream:
            if chunk.candidates and chunk.candidates[0].content.parts:
                for part in chunk.candidates[0].content.parts:
                    if hasattr(part, 'thought') and part.thought:
                        yield {
                            "type": "thinking",
                            "content": part.text
                        }
                    else:
                        response_text += part.text
                        yield {
                            "type": "response",
                            "content": part.text
                        }
        
        # Extract and yield charts
        charts = self._extract_charts(response_text)
        for chart in charts:
            yield {
                "type": "chart",
                "content": chart
            }

    def _extract_charts(self, text: str) -> List[Dict[str, Any]]:
        """Extract chart JSON blocks from response text."""
        charts = []
        
        # Find ```chart blocks
        pattern = r'```chart\s*\n(.*?)\n```'
        matches = re.findall(pattern, text, re.DOTALL)
        
        for match in matches:
            try:
                chart_data = json.loads(match)
                # Validate chart has required fields
                if chart_data.get("type") and chart_data.get("data"):
                    charts.append(chart_data)
            except json.JSONDecodeError:
                continue
        
        return charts

    def _mock_analysis(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Generate comprehensive mock response for demo."""
        query = context.get("query", "").lower()
        files = context.get("files", [])
        
        thinking_trace = [
            "ðŸ”¬ Initializing comprehensive analysis pipeline...",
            "ðŸ“Š Extracting features and patterns from input data...",
            "ðŸ§¬ Cross-referencing with biomedical knowledge base...",
            "ðŸ“ˆ Computing statistical correlations and significance...",
            "ðŸŽ¯ Generating data visualizations for key findings...",
            "ðŸ’¡ Synthesizing insights and recommendations..."
        ]
        
        # Generate contextual charts based on query
        charts = []
        
        # Chart 1: Always include a confidence/quality metrics chart
        charts.append({
            "type": "radar",
            "title": "Analysis Quality Metrics",
            "data": {
                "categories": ["Data Quality", "Statistical Power", "Reproducibility", "Clinical Relevance", "Novelty"],
                "values": [92, 85, 78, 88, 72]
            },
            "insights": "High confidence in data quality and clinical relevance. Statistical power is adequate for preliminary conclusions."
        })
        
        # Chart 2: Context-specific chart
        if "cancer" in query or "mutation" in query or "p53" in query or "tumor" in query:
            charts.append({
                "type": "heatmap",
                "title": "Mutation Frequency Across Cancer Types",
                "data": {
                    "z": [[85, 42, 58, 31], [38, 91, 45, 67], [22, 48, 73, 44], [61, 35, 52, 88]],
                    "x": ["Lung", "Breast", "Colorectal", "Liver"],
                    "y": ["TP53", "BRCA1", "KRAS", "APC"]
                },
                "insights": "TP53 mutations show highest prevalence in lung cancer (85%). BRCA1 mutations are predominant in breast cancer samples."
            })
            charts.append({
                "type": "bar",
                "title": "Mutation Impact Score by Gene",
                "data": {
                    "labels": ["TP53", "BRCA1", "KRAS", "APC", "PIK3CA", "EGFR"],
                    "values": [9.2, 8.7, 7.8, 7.2, 6.5, 6.1]
                },
                "insights": "TP53 and BRCA1 show highest functional impact scores, indicating critical roles in oncogenesis."
            })
        
        elif "protein" in query or "structure" in query or "binding" in query:
            charts.append({
                "type": "scatter",
                "title": "Binding Affinity vs. Molecular Weight",
                "data": {
                    "x": [25.4, 32.1, 45.6, 51.2, 62.3, 74.5, 85.2, 92.1],
                    "y": [8.2, 7.5, 9.1, 6.8, 8.8, 7.2, 9.5, 8.1],
                    "sizes": [20, 25, 30, 22, 35, 28, 40, 32]
                },
                "insights": "Strong positive correlation (r=0.72) between molecular weight and binding affinity in the 45-85 kDa range."
            })
            charts.append({
                "type": "line",
                "title": "Protein Stability Over pH Range",
                "data": {
                    "x": ["pH 4", "pH 5", "pH 6", "pH 7", "pH 8", "pH 9", "pH 10"],
                    "y": [45, 68, 89, 95, 92, 78, 52]
                },
                "insights": "Optimal stability at physiological pH (7.0-8.0). Significant denaturation below pH 5 and above pH 9."
            })
        
        elif "gene" in query or "expression" in query or "rna" in query:
            charts.append({
                "type": "line",
                "title": "Gene Expression Time Course",
                "data": {
                    "x": ["0h", "6h", "12h", "24h", "48h", "72h", "96h"],
                    "y": [1.0, 2.3, 4.8, 8.2, 6.5, 4.1, 2.8]
                },
                "insights": "Peak expression at 24h post-treatment (8.2x baseline). Expression returns to near-baseline by 96h."
            })
            charts.append({
                "type": "heatmap",
                "title": "Pathway Enrichment Analysis",
                "data": {
                    "z": [[4.2, 2.8, 1.5], [3.1, 4.5, 2.2], [1.8, 3.5, 4.8], [2.5, 1.2, 3.9]],
                    "x": ["Treatment A", "Treatment B", "Control"],
                    "y": ["Apoptosis", "Cell Cycle", "DNA Repair", "Metabolism"]
                },
                "insights": "Treatment A shows strongest enrichment in apoptotic pathways. Treatment B primarily affects cell cycle regulation."
            })
        
        else:
            # Default scientific charts
            charts.append({
                "type": "bar",
                "title": "Analysis Confidence by Category",
                "data": {
                    "labels": ["Structure", "Function", "Interaction", "Localization", "Stability"],
                    "values": [0.92, 0.85, 0.78, 0.88, 0.81]
                },
                "insights": "Highest confidence in structural and localization predictions. Interaction predictions may require experimental validation."
            })
            charts.append({
                "type": "pie",
                "title": "Data Source Distribution",
                "data": {
                    "labels": ["Experimental", "Computational", "Literature", "Database"],
                    "values": [42, 28, 18, 12]
                },
                "insights": "Analysis primarily based on experimental data (42%), supplemented by computational predictions."
            })
        
        # Build comprehensive response
        response = f"""## ðŸ“‹ Executive Summary

Based on comprehensive analysis of your query: **"{query[:80]}{'...' if len(query) > 80 else ''}"**

I've identified **{len(charts)} key findings** with high statistical confidence. The analysis incorporates multimodal data integration and cross-referencing with established biomedical literature.

---

## ðŸ”¬ Detailed Analysis

### 1. Data Quality Assessment
- **Input Quality Score**: 92/100
- **Data Completeness**: High
- **Statistical Power**: Adequate for preliminary conclusions

### 2. Key Findings

{'**Mutation Analysis**' if 'cancer' in query or 'mutation' in query else '**Pattern Recognition**'}

The analysis reveals several statistically significant patterns (p < 0.05) that warrant further investigation:

1. **Primary Finding**: Identified strong correlations between the queried parameters and known biological pathways.
   
2. **Secondary Observations**: 
   - Cross-validation with existing literature supports the hypothesis
   - Multiple independent lines of evidence converge on similar conclusions

3. **Statistical Summary**:
   - Confidence Interval: 95%
   - Effect Size: Large (Cohen's d > 0.8)
   - Sample adequacy: Sufficient for preliminary conclusions

---

## ðŸ“Š Data Visualizations

I've generated **{len(charts)} visualizations** to illustrate the key findings. Each chart includes actionable insights for your research.

---

## ðŸ’¡ Recommendations

### Immediate Actions
1. Review the generated visualizations for patterns relevant to your hypothesis
2. Cross-validate findings with independent datasets
3. Consider experimental validation for computational predictions

### Next Steps
1. **Literature Review**: Compare with recent publications in the field
2. **Experimental Design**: Plan validation experiments based on predictions
3. **Collaboration**: Consider consulting domain experts for interpretation

---

## âš ï¸ Limitations & Caveats

- Results should be validated experimentally before clinical application
- Statistical associations do not imply causation
- Model predictions may vary with different training datasets

---

## ðŸ§  Session Memory

This analysis has been stored in your research session. Future queries will incorporate these findings for enhanced contextual analysis.
"""
        
        if files:
            response += f"\n\n---\n*ðŸ“ Analyzed {len(files)} file(s): {', '.join(f['filename'] for f in files)}*"
        
        return {
            "response": response,
            "thinking_trace": thinking_trace,
            "chart_data": charts,
            "model": "gemini-2.5-pro (demo)",
            "thinking_level": "high"
        }

    async def _mock_stream(self, context: Dict[str, Any]) -> AsyncGenerator[Dict[str, Any], None]:
        """Generate mock streaming response."""
        import asyncio
        
        thinking_steps = [
            "ðŸ”¬ Initializing multimodal analysis pipeline...",
            "ðŸ“Š Processing input data and extracting features...",
            "ðŸ§¬ Applying deep reasoning algorithms...",
            "ðŸ“ˆ Generating data visualizations...",
            "ðŸ’¡ Synthesizing findings and recommendations..."
        ]
        
        for step in thinking_steps:
            yield {"type": "thinking", "content": step}
            await asyncio.sleep(0.3)
        
        response = self._mock_analysis(context)
        
        # Stream the response in chunks
        text = response["response"]
        chunk_size = 100
        for i in range(0, len(text), chunk_size):
            yield {"type": "response", "content": text[i:i+chunk_size]}
            await asyncio.sleep(0.05)
        
        # Yield charts
        for chart in response.get("chart_data", []):
            yield {"type": "chart", "content": chart}
